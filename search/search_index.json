{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PyWhisperCpp API Reference","text":""},{"location":"#pywhispercpp.model","title":"pywhispercpp.model","text":"<p>This module contains a simple Python API on-top of the C-style whisper.cpp API.</p>"},{"location":"#pywhispercpp.model.Segment","title":"Segment","text":"<pre><code>Segment(t0, t1, text)\n</code></pre> <p>A small class representing a transcription segment</p> <p>Parameters:</p> <ul> <li> <code>t0</code>               (<code>int</code>)           \u2013            <p>start time</p> </li> <li> <code>t1</code>               (<code>int</code>)           \u2013            <p>end time</p> </li> <li> <code>text</code>               (<code>str</code>)           \u2013            <p>text</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>def __init__(self, t0: int, t1: int, text: str):\n    \"\"\"\n    :param t0: start time\n    :param t1: end time\n    :param text: text\n    \"\"\"\n    self.t0 = t0\n    self.t1 = t1\n    self.text = text\n</code></pre>"},{"location":"#pywhispercpp.model.Model","title":"Model","text":"<pre><code>Model(\n    model=\"tiny\",\n    models_dir=None,\n    params_sampling_strategy=0,\n    redirect_whispercpp_logs_to=False,\n    **params\n)\n</code></pre> <p>This classes defines a Whisper.cpp model.</p> <p>Example usage. <pre><code>model = Model('base.en', n_threads=6)\nsegments = model.transcribe('file.mp3')\nfor segment in segments:\n    print(segment.text)\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>str</code>, default:                   <code>'tiny'</code> )           \u2013            <p>The name of the model, one of the AVAILABLE_MODELS, (default to <code>tiny</code>), or a direct path to a <code>ggml</code> model.</p> </li> <li> <code>models_dir</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The directory where the models are stored, or where they will be downloaded if they don't exist, default to MODELS_DIR <li> <code>params_sampling_strategy</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>0 -&gt; GREEDY, else BEAM_SEARCH</p> </li> <li> <code>redirect_whispercpp_logs_to</code>               (<code>Union[bool, TextIO, str, None]</code>, default:                   <code>False</code> )           \u2013            <p>where to redirect the whisper.cpp logs, default to False (no redirection), accepts str file path, sys.stdout, sys.stderr, or use None to redirect to devnull</p> </li> <li> <code>params</code>           \u2013            <p>keyword arguments for different whisper.cpp parameters, see PARAMS_SCHEMA</p> </li> Source code in <code>pywhispercpp/model.py</code> <pre><code>def __init__(self,\n             model: str = 'tiny',\n             models_dir: str = None,\n             params_sampling_strategy: int = 0,\n             redirect_whispercpp_logs_to: Union[bool, TextIO, str, None] = False,\n             **params):\n    \"\"\"\n    :param model: The name of the model, one of the [AVAILABLE_MODELS](/pywhispercpp/#pywhispercpp.constants.AVAILABLE_MODELS),\n                    (default to `tiny`), or a direct path to a `ggml` model.\n    :param models_dir: The directory where the models are stored, or where they will be downloaded if they don't\n                        exist, default to [MODELS_DIR](/pywhispercpp/#pywhispercpp.constants.MODELS_DIR) &lt;user_data_dir/pywhsipercpp/models&gt;\n    :param params_sampling_strategy: 0 -&gt; GREEDY, else BEAM_SEARCH\n    :param redirect_whispercpp_logs_to: where to redirect the whisper.cpp logs, default to False (no redirection), accepts str file path, sys.stdout, sys.stderr, or use None to redirect to devnull\n    :param params: keyword arguments for different whisper.cpp parameters,\n                    see [PARAMS_SCHEMA](/pywhispercpp/#pywhispercpp.constants.PARAMS_SCHEMA)\n    \"\"\"\n    if Path(model).is_file():\n        self.model_path = model\n    else:\n        self.model_path = utils.download_model(model, models_dir)\n    self._ctx = None\n    self._sampling_strategy = pw.whisper_sampling_strategy.WHISPER_SAMPLING_GREEDY if params_sampling_strategy == 0 else \\\n        pw.whisper_sampling_strategy.WHISPER_SAMPLING_BEAM_SEARCH\n    self._params = pw.whisper_full_default_params(self._sampling_strategy)\n    # assign params\n    self._set_params(params)\n    self.redirect_whispercpp_logs_to = redirect_whispercpp_logs_to\n    # init the model\n    self._init_model()\n</code></pre>"},{"location":"#pywhispercpp.model.Model.transcribe","title":"transcribe","text":"<pre><code>transcribe(\n    media,\n    n_processors=None,\n    new_segment_callback=None,\n    **params\n)\n</code></pre> <p>Transcribes the media provided as input and returns list of <code>Segment</code> objects. Accepts a media_file path (audio/video) or a raw numpy array.</p> <p>Parameters:</p> <ul> <li> <code>media</code>               (<code>Union[str, ndarray]</code>)           \u2013            <p>Media file path or a numpy array</p> </li> <li> <code>n_processors</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>if not None, it will run the transcription on multiple processes binding to whisper.cpp/whisper_full_parallel &gt; Split the input audio in chunks and process each chunk separately using whisper_full()</p> </li> <li> <code>new_segment_callback</code>               (<code>Callable[[Segment], None]</code>, default:                   <code>None</code> )           \u2013            <p>callback function that will be called when a new segment is generated</p> </li> <li> <code>params</code>           \u2013            <p>keyword arguments for different whisper.cpp parameters, see ::: constants.PARAMS_SCHEMA</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[Segment]</code>           \u2013            <p>List of transcription segments</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>def transcribe(self,\n               media: Union[str, np.ndarray],\n               n_processors: int = None,\n               new_segment_callback: Callable[[Segment], None] = None,\n               **params) -&gt; List[Segment]:\n    \"\"\"\n    Transcribes the media provided as input and returns list of `Segment` objects.\n    Accepts a media_file path (audio/video) or a raw numpy array.\n\n    :param media: Media file path or a numpy array\n    :param n_processors: if not None, it will run the transcription on multiple processes\n                         binding to whisper.cpp/whisper_full_parallel\n                         &gt; Split the input audio in chunks and process each chunk separately using whisper_full()\n    :param new_segment_callback: callback function that will be called when a new segment is generated\n    :param params: keyword arguments for different whisper.cpp parameters, see ::: constants.PARAMS_SCHEMA\n\n    :return: List of transcription segments\n    \"\"\"\n    if type(media) is np.ndarray:\n        audio = media\n    else:\n        if not Path(media).exists():\n            raise FileNotFoundError(media)\n        audio = self._load_audio(media)\n    # update params if any\n    self._set_params(params)\n\n    # setting up callback\n    if new_segment_callback:\n        Model._new_segment_callback = new_segment_callback\n        pw.assign_new_segment_callback(self._params, Model.__call_new_segment_callback)\n\n    # run inference\n    start_time = time()\n    logger.info(\"Transcribing ...\")\n    res = self._transcribe(audio, n_processors=n_processors)\n    end_time = time()\n    logger.info(f\"Inference time: {end_time - start_time:.3f} s\")\n    return res\n</code></pre>"},{"location":"#pywhispercpp.model.Model.get_params","title":"get_params","text":"<pre><code>get_params()\n</code></pre> <p>Returns a <code>dict</code> representation of the actual params</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>params dict</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>def get_params(self) -&gt; dict:\n    \"\"\"\n    Returns a `dict` representation of the actual params\n\n    :return: params dict\n    \"\"\"\n    res = {}\n    for param in dir(self._params):\n        if param.startswith('__'):\n            continue\n        res[param] = getattr(self._params, param)\n    return res\n</code></pre>"},{"location":"#pywhispercpp.model.Model.get_params_schema","title":"get_params_schema  <code>staticmethod</code>","text":"<pre><code>get_params_schema()\n</code></pre> <p>A simple link to ::: constants.PARAMS_SCHEMA</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>dict of params schema</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>@staticmethod\ndef get_params_schema() -&gt; dict:\n    \"\"\"\n    A simple link to ::: constants.PARAMS_SCHEMA\n    :return: dict of params schema\n    \"\"\"\n    return constants.PARAMS_SCHEMA\n</code></pre>"},{"location":"#pywhispercpp.model.Model.lang_max_id","title":"lang_max_id  <code>staticmethod</code>","text":"<pre><code>lang_max_id()\n</code></pre> <p>Returns number of supported languages. Direct binding to whisper.cpp/lang_max_id</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>@staticmethod\ndef lang_max_id() -&gt; int:\n    \"\"\"\n    Returns number of supported languages.\n    Direct binding to whisper.cpp/lang_max_id\n    :return:\n    \"\"\"\n    return pw.whisper_lang_max_id()\n</code></pre>"},{"location":"#pywhispercpp.model.Model.print_timings","title":"print_timings","text":"<pre><code>print_timings()\n</code></pre> <p>Direct binding to whisper.cpp/whisper_print_timings</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>def print_timings(self) -&gt; None:\n    \"\"\"\n    Direct binding to whisper.cpp/whisper_print_timings\n\n    :return: None\n    \"\"\"\n    pw.whisper_print_timings(self._ctx)\n</code></pre>"},{"location":"#pywhispercpp.model.Model.system_info","title":"system_info  <code>staticmethod</code>","text":"<pre><code>system_info()\n</code></pre> <p>Direct binding to whisper.cpp/whisper_print_system_info</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>@staticmethod\ndef system_info() -&gt; None:\n    \"\"\"\n    Direct binding to whisper.cpp/whisper_print_system_info\n\n    :return: None\n    \"\"\"\n    return pw.whisper_print_system_info()\n</code></pre>"},{"location":"#pywhispercpp.model.Model.available_languages","title":"available_languages  <code>staticmethod</code>","text":"<pre><code>available_languages()\n</code></pre> <p>Returns a list of supported language codes</p> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>list of supported language codes</p> </li> </ul> Source code in <code>pywhispercpp/model.py</code> <pre><code>@staticmethod\ndef available_languages() -&gt; list:\n    \"\"\"\n    Returns a list of supported language codes\n\n    :return: list of supported language codes\n    \"\"\"\n    n = pw.whisper_lang_max_id()\n    res = []\n    for i in range(n):\n        res.append(pw.whisper_lang_str(i))\n    return res\n</code></pre>"},{"location":"#pywhispercpp.constants","title":"pywhispercpp.constants","text":"<p>Constants</p>"},{"location":"#pywhispercpp.constants.WHISPER_SAMPLE_RATE","title":"WHISPER_SAMPLE_RATE  <code>module-attribute</code>","text":"<pre><code>WHISPER_SAMPLE_RATE = WHISPER_SAMPLE_RATE\n</code></pre>"},{"location":"#pywhispercpp.constants.MODELS_BASE_URL","title":"MODELS_BASE_URL  <code>module-attribute</code>","text":"<pre><code>MODELS_BASE_URL = (\n    \"https://huggingface.co/ggerganov/whisper.cpp\"\n)\n</code></pre>"},{"location":"#pywhispercpp.constants.MODELS_PREFIX_URL","title":"MODELS_PREFIX_URL  <code>module-attribute</code>","text":"<pre><code>MODELS_PREFIX_URL = 'resolve/main/ggml'\n</code></pre>"},{"location":"#pywhispercpp.constants.PACKAGE_NAME","title":"PACKAGE_NAME  <code>module-attribute</code>","text":"<pre><code>PACKAGE_NAME = 'pywhispercpp'\n</code></pre>"},{"location":"#pywhispercpp.constants.MODELS_DIR","title":"MODELS_DIR  <code>module-attribute</code>","text":"<pre><code>MODELS_DIR = Path(user_data_dir(PACKAGE_NAME)) / 'models'\n</code></pre>"},{"location":"#pywhispercpp.constants.AVAILABLE_MODELS","title":"AVAILABLE_MODELS  <code>module-attribute</code>","text":"<pre><code>AVAILABLE_MODELS = [\n    \"base\",\n    \"base-q5_1\",\n    \"base.en\",\n    \"base.en-q5_1\",\n    \"large-v1\",\n    \"large-v2\",\n    \"large-v2-q5_0\",\n    \"large-v3\",\n    \"large-v3-q5_0\",\n    \"large-v3-turbo\",\n    \"large-v3-turbo-q5_0\",\n    \"medium\",\n    \"medium-q5_0\",\n    \"medium.en\",\n    \"medium.en-q5_0\",\n    \"small\",\n    \"small-q5_1\",\n    \"small.en\",\n    \"small.en-q5_1\",\n    \"tiny\",\n    \"tiny-q5_1\",\n    \"tiny.en\",\n    \"tiny.en-q5_1\",\n    \"tiny.en-q8_0\",\n]\n</code></pre>"},{"location":"#pywhispercpp.constants.PARAMS_SCHEMA","title":"PARAMS_SCHEMA  <code>module-attribute</code>","text":"<pre><code>PARAMS_SCHEMA = {\n    \"n_threads\": {\n        \"type\": int,\n        \"description\": \"Number of threads to allocate for the inferencedefault to min(4, available hardware_concurrency)\",\n        \"options\": None,\n        \"default\": None,\n    },\n    \"n_max_text_ctx\": {\n        \"type\": int,\n        \"description\": \"max tokens to use from past text as prompt for the decoder\",\n        \"options\": None,\n        \"default\": 16384,\n    },\n    \"offset_ms\": {\n        \"type\": int,\n        \"description\": \"start offset in ms\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"duration_ms\": {\n        \"type\": int,\n        \"description\": \"audio duration to process in ms\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"translate\": {\n        \"type\": bool,\n        \"description\": \"whether to translate the audio to English\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"no_context\": {\n        \"type\": bool,\n        \"description\": \"do not use past transcription (if any) as initial prompt for the decoder\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"single_segment\": {\n        \"type\": bool,\n        \"description\": \"force single segment output (useful for streaming)\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"print_special\": {\n        \"type\": bool,\n        \"description\": \"print special tokens (e.g. &lt;SOT&gt;, &lt;EOT&gt;, &lt;BEG&gt;, etc.)\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"print_progress\": {\n        \"type\": bool,\n        \"description\": \"print progress information\",\n        \"options\": None,\n        \"default\": True,\n    },\n    \"print_realtime\": {\n        \"type\": bool,\n        \"description\": \"print results from within whisper.cpp (avoid it, use callback instead)\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"print_timestamps\": {\n        \"type\": bool,\n        \"description\": \"print timestamps for each text segment when printing realtime\",\n        \"options\": None,\n        \"default\": True,\n    },\n    \"token_timestamps\": {\n        \"type\": bool,\n        \"description\": \"enable token-level timestamps\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"thold_pt\": {\n        \"type\": float,\n        \"description\": \"timestamp token probability threshold (~0.01)\",\n        \"options\": None,\n        \"default\": 0.01,\n    },\n    \"thold_ptsum\": {\n        \"type\": float,\n        \"description\": \"timestamp token sum probability threshold (~0.01)\",\n        \"options\": None,\n        \"default\": 0.01,\n    },\n    \"max_len\": {\n        \"type\": int,\n        \"description\": \"max segment length in characters\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"split_on_word\": {\n        \"type\": bool,\n        \"description\": \"split on word rather than on token (when used with max_len)\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"max_tokens\": {\n        \"type\": int,\n        \"description\": \"max tokens per segment (0 = no limit)\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"audio_ctx\": {\n        \"type\": int,\n        \"description\": \"overwrite the audio context size (0 = use default)\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"initial_prompt\": {\n        \"type\": str,\n        \"description\": \"Initial prompt, these are prepended to any existing text context from a previous call\",\n        \"options\": None,\n        \"default\": None,\n    },\n    \"prompt_tokens\": {\n        \"type\": Tuple,\n        \"description\": \"tokens to provide to the whisper decoder as initial prompt\",\n        \"options\": None,\n        \"default\": None,\n    },\n    \"prompt_n_tokens\": {\n        \"type\": int,\n        \"description\": \"tokens to provide to the whisper decoder as initial prompt\",\n        \"options\": None,\n        \"default\": 0,\n    },\n    \"language\": {\n        \"type\": str,\n        \"description\": 'for auto-detection, set to None, \"\" or \"auto\"',\n        \"options\": None,\n        \"default\": \"en\",\n    },\n    \"suppress_blank\": {\n        \"type\": bool,\n        \"description\": \"common decoding parameters\",\n        \"options\": None,\n        \"default\": True,\n    },\n    \"suppress_non_speech_tokens\": {\n        \"type\": bool,\n        \"description\": \"common decoding parameters\",\n        \"options\": None,\n        \"default\": False,\n    },\n    \"temperature\": {\n        \"type\": float,\n        \"description\": \"initial decoding temperature\",\n        \"options\": None,\n        \"default\": 0.0,\n    },\n    \"max_initial_ts\": {\n        \"type\": float,\n        \"description\": \"max_initial_ts\",\n        \"options\": None,\n        \"default\": 1.0,\n    },\n    \"length_penalty\": {\n        \"type\": float,\n        \"description\": \"length_penalty\",\n        \"options\": None,\n        \"default\": -1.0,\n    },\n    \"temperature_inc\": {\n        \"type\": float,\n        \"description\": \"temperature_inc\",\n        \"options\": None,\n        \"default\": 0.2,\n    },\n    \"entropy_thold\": {\n        \"type\": float,\n        \"description\": 'similar to OpenAI\\'s \"compression_ratio_threshold\"',\n        \"options\": None,\n        \"default\": 2.4,\n    },\n    \"logprob_thold\": {\n        \"type\": float,\n        \"description\": \"logprob_thold\",\n        \"options\": None,\n        \"default\": -1.0,\n    },\n    \"no_speech_thold\": {\n        \"type\": float,\n        \"description\": \"no_speech_thold\",\n        \"options\": None,\n        \"default\": 0.6,\n    },\n    \"greedy\": {\n        \"type\": dict,\n        \"description\": \"greedy\",\n        \"options\": None,\n        \"default\": {\"best_of\": -1},\n    },\n    \"beam_search\": {\n        \"type\": dict,\n        \"description\": \"beam_search\",\n        \"options\": None,\n        \"default\": {\"beam_size\": -1, \"patience\": -1.0},\n    },\n}\n</code></pre>"},{"location":"#pywhispercpp.utils","title":"pywhispercpp.utils","text":"<p>Helper functions</p>"},{"location":"#pywhispercpp.utils.download_model","title":"download_model","text":"<pre><code>download_model(\n    model_name, download_dir=None, chunk_size=1024\n)\n</code></pre> <p>Helper function to download the <code>ggml</code> models</p> <p>Parameters:</p> <ul> <li> <code>model_name</code>               (<code>str</code>)           \u2013            <p>name of the model, one of ::: constants.AVAILABLE_MODELS</p> </li> <li> <code>download_dir</code>           \u2013            <p>Where to store the models</p> </li> <li> <code>chunk_size</code>           \u2013            <p>size of the download chunk</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Absolute path of the downloaded model</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def download_model(model_name: str, download_dir=None, chunk_size=1024) -&gt; str:\n    \"\"\"\n    Helper function to download the `ggml` models\n    :param model_name: name of the model, one of ::: constants.AVAILABLE_MODELS\n    :param download_dir: Where to store the models\n    :param chunk_size: size of the download chunk\n\n    :return: Absolute path of the downloaded model\n    \"\"\"\n    if model_name not in AVAILABLE_MODELS:\n        logger.error(f\"Invalid model name `{model_name}`, available models are: {AVAILABLE_MODELS}\")\n        return\n    if download_dir is None:\n        download_dir = MODELS_DIR\n        logger.info(f\"No download directory was provided, models will be downloaded to {download_dir}\")\n\n    os.makedirs(download_dir, exist_ok=True)\n\n    url = _get_model_url(model_name=model_name)\n    file_path = Path(download_dir) / os.path.basename(url)\n    # check if the file is already there\n    if file_path.exists():\n        logger.info(f\"Model {model_name} already exists in {download_dir}\")\n    else:\n        # download it from huggingface\n        resp = requests.get(url, stream=True)\n        total = int(resp.headers.get('content-length', 0))\n\n        progress_bar = tqdm(desc=f\"Downloading Model {model_name} ...\",\n                            total=total,\n                            unit='iB',\n                            unit_scale=True,\n                            unit_divisor=1024)\n\n        try:\n            with open(file_path, 'wb') as file, progress_bar:\n                for data in resp.iter_content(chunk_size=chunk_size):\n                    size = file.write(data)\n                    progress_bar.update(size)\n            logger.info(f\"Model downloaded to {file_path.absolute()}\")\n        except Exception as e:\n            # error download, just remove the file\n            os.remove(file_path)\n            raise e\n    return str(file_path.absolute())\n</code></pre>"},{"location":"#pywhispercpp.utils.to_timestamp","title":"to_timestamp","text":"<pre><code>to_timestamp(t, separator=',')\n</code></pre> <p>376 -&gt; 00:00:03,760 1344 -&gt; 00:00:13,440</p> <p>Implementation from <code>whisper.cpp/examples/main</code></p> <p>Parameters:</p> <ul> <li> <code>t</code>               (<code>int</code>)           \u2013            <p>input time from whisper timestamps</p> </li> <li> <code>separator</code>           \u2013            <p>seprator between seconds and milliseconds</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>time representation in hh: mm: ss[separator]ms</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def to_timestamp(t: int, separator=',') -&gt; str:\n    \"\"\"\n    376 -&gt; 00:00:03,760\n    1344 -&gt; 00:00:13,440\n\n    Implementation from `whisper.cpp/examples/main`\n\n    :param t: input time from whisper timestamps\n    :param separator: seprator between seconds and milliseconds\n    :return: time representation in hh: mm: ss[separator]ms\n    \"\"\"\n    # logic exactly from whisper.cpp\n\n    msec = t * 10\n    hr = msec // (1000 * 60 * 60)\n    msec = msec - hr * (1000 * 60 * 60)\n    min = msec // (1000 * 60)\n    msec = msec - min * (1000 * 60)\n    sec = msec // 1000\n    msec = msec - sec * 1000\n    return f\"{int(hr):02,.0f}:{int(min):02,.0f}:{int(sec):02,.0f}{separator}{int(msec):03,.0f}\"\n</code></pre>"},{"location":"#pywhispercpp.utils.output_txt","title":"output_txt","text":"<pre><code>output_txt(segments, output_file_path)\n</code></pre> <p>Creates a raw text from a list of segments</p> <p>Implementation from <code>whisper.cpp/examples/main</code></p> <p>Parameters:</p> <ul> <li> <code>segments</code>               (<code>list</code>)           \u2013            <p>list of segments</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>path of the file</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def output_txt(segments: list, output_file_path: str) -&gt; str:\n    \"\"\"\n    Creates a raw text from a list of segments\n\n    Implementation from `whisper.cpp/examples/main`\n\n    :param segments: list of segments\n    :return: path of the file\n    \"\"\"\n    if not output_file_path.endswith('.txt'):\n        output_file_path = output_file_path + '.txt'\n\n    absolute_path = Path(output_file_path).absolute()\n\n    with open(str(absolute_path), 'w') as file:\n        for seg in segments:\n            file.write(seg.text)\n            file.write('\\n')\n    return absolute_path\n</code></pre>"},{"location":"#pywhispercpp.utils.output_vtt","title":"output_vtt","text":"<pre><code>output_vtt(segments, output_file_path)\n</code></pre> <p>Creates a vtt file from a list of segments</p> <p>Implementation from <code>whisper.cpp/examples/main</code></p> <p>Parameters:</p> <ul> <li> <code>segments</code>               (<code>list</code>)           \u2013            <p>list of segments</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Absolute path of the file</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def output_vtt(segments: list, output_file_path: str) -&gt; str:\n    \"\"\"\n    Creates a vtt file from a list of segments\n\n    Implementation from `whisper.cpp/examples/main`\n\n    :param segments: list of segments\n    :return: path of the file\n\n    :return: Absolute path of the file\n    \"\"\"\n    if not output_file_path.endswith('.vtt'):\n        output_file_path = output_file_path + '.vtt'\n\n    absolute_path = Path(output_file_path).absolute()\n\n    with open(absolute_path, 'w') as file:\n        file.write(\"WEBVTT\\n\\n\")\n        for seg in segments:\n            file.write(f\"{to_timestamp(seg.t0, separator='.')} --&gt; {to_timestamp(seg.t1, separator='.')}\\n\")\n            file.write(f\"{seg.text}\\n\\n\")\n    return absolute_path\n</code></pre>"},{"location":"#pywhispercpp.utils.output_srt","title":"output_srt","text":"<pre><code>output_srt(segments, output_file_path)\n</code></pre> <p>Creates a srt file from a list of segments</p> <p>Parameters:</p> <ul> <li> <code>segments</code>               (<code>list</code>)           \u2013            <p>list of segments</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Absolute path of the file</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def output_srt(segments: list, output_file_path: str) -&gt; str:\n    \"\"\"\n    Creates a srt file from a list of segments\n\n    :param segments: list of segments\n    :return: path of the file\n\n    :return: Absolute path of the file\n    \"\"\"\n    if not output_file_path.endswith('.srt'):\n        output_file_path = output_file_path + '.srt'\n\n    absolute_path = Path(output_file_path).absolute()\n\n    with open(absolute_path, 'w') as file:\n        for i in range(len(segments)):\n            seg = segments[i]\n            file.write(f\"{i+1}\\n\")\n            file.write(f\"{to_timestamp(seg.t0, separator=',')} --&gt; {to_timestamp(seg.t1, separator=',')}\\n\")\n            file.write(f\"{seg.text}\\n\\n\")\n    return absolute_path\n</code></pre>"},{"location":"#pywhispercpp.utils.output_csv","title":"output_csv","text":"<pre><code>output_csv(segments, output_file_path)\n</code></pre> <p>Creates a srt file from a list of segments</p> <p>Parameters:</p> <ul> <li> <code>segments</code>               (<code>list</code>)           \u2013            <p>list of segments</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>Absolute path of the file</p> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>def output_csv(segments: list, output_file_path: str) -&gt; str:\n    \"\"\"\n    Creates a srt file from a list of segments\n\n    :param segments: list of segments\n    :return: path of the file\n\n    :return: Absolute path of the file\n    \"\"\"\n    if not output_file_path.endswith('.csv'):\n        output_file_path = output_file_path + '.csv'\n\n    absolute_path = Path(output_file_path).absolute()\n\n    with open(absolute_path, 'w') as file:\n        for seg in segments:\n            file.write(f\"{10 * seg.t0}, {10 * seg.t1}, \\\"{seg.text}\\\"\\n\")\n    return absolute_path\n</code></pre>"},{"location":"#pywhispercpp.utils.redirect_stderr","title":"redirect_stderr","text":"<pre><code>redirect_stderr(to=False)\n</code></pre> <p>Redirect stderr to the specified target.</p> <p>Parameters:</p> <ul> <li> <code>to</code>           \u2013            <ul> <li>None to suppress output (redirect to devnull), - sys.stdout to redirect to stdout, - A file path (str) to redirect to a file, - False to do nothing (no redirection).</li> </ul> </li> </ul> Source code in <code>pywhispercpp/utils.py</code> <pre><code>@contextlib.contextmanager\ndef redirect_stderr(to=False) -&gt; None:\n    \"\"\"\n    Redirect stderr to the specified target.\n\n    :param to:\n        - None to suppress output (redirect to devnull),\n        - sys.stdout to redirect to stdout,\n        - A file path (str) to redirect to a file,\n        - False to do nothing (no redirection).\n    \"\"\"\n\n    if to is False:\n        # do nothing\n        yield\n        return\n\n    sys.stderr.flush()\n    try:\n        original_stderr_fd = sys.stderr.fileno()\n        has_fileno = True\n    except (AttributeError, OSError):\n        # Jupyter or non-standard stderr implementations\n        has_fileno = False\n\n    if has_fileno:\n        if to is None:\n            target_fd = os.open(os.devnull, os.O_WRONLY)\n        elif isinstance(to, str):\n            file = open(to, 'w')\n            target_fd = file.fileno()\n        elif hasattr(to, 'fileno'):\n            target_fd = to.fileno()\n        else:\n            raise ValueError(\"Invalid `to` parameter; must be None, a filepath string, or sys.stdout/sys.stderr.\")\n        os.dup2(target_fd, original_stderr_fd)\n        try:\n            yield\n        finally:\n            os.dup2(original_stderr_fd, original_stderr_fd)\n            if isinstance(to, str):\n                file.close()\n            elif to is None:\n                os.close(target_fd)\n    else:\n        # Replace sys.stderr directly\n        original_stderr = sys.stderr\n        if to is None:\n            sys.stderr = open(os.devnull, 'w')\n        elif isinstance(to, str):\n            sys.stderr = open(to, 'w')\n        elif hasattr(to, 'write'):\n            sys.stderr = to\n        try:\n            yield\n        finally:\n            sys.stderr = original_stderr\n            if isinstance(to, str) or to is None:\n                sys.stderr.close()\n</code></pre>"},{"location":"#pywhispercpp.examples","title":"pywhispercpp.examples","text":""},{"location":"#pywhispercpp.examples.assistant","title":"assistant","text":"<p>A simple example showcasing the use of <code>pywhispercpp</code> as an assistant. The idea is to use a <code>VAD</code> to detect speech (in this example we used webrtcvad), and when speech is detected we run the inference.</p>"},{"location":"#pywhispercpp.examples.assistant.Assistant","title":"Assistant","text":"<pre><code>Assistant(\n    model=\"tiny\",\n    input_device=None,\n    silence_threshold=8,\n    q_threshold=16,\n    block_duration=30,\n    commands_callback=None,\n    model_log_level=logging.INFO,\n    **model_params\n)\n</code></pre> <p>Assistant class</p> <p>Example usage <pre><code>from pywhispercpp.examples.assistant import Assistant\n\nmy_assistant = Assistant(commands_callback=print, n_threads=8)\nmy_assistant.start()\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>model</code>           \u2013            <p>whisper.cpp model name or a direct path to a<code>ggml</code> model</p> </li> <li> <code>input_device</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>The input device (aka microphone), keep it None to take the default</p> </li> <li> <code>silence_threshold</code>               (<code>int</code>, default:                   <code>8</code> )           \u2013            <p>The duration of silence after which the inference will be running</p> </li> <li> <code>q_threshold</code>               (<code>int</code>, default:                   <code>16</code> )           \u2013            <p>The inference won't be running until the data queue is having at least <code>q_threshold</code> elements</p> </li> <li> <code>block_duration</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>minimum time audio updates in ms</p> </li> <li> <code>commands_callback</code>               (<code>Callable[[str], None]</code>, default:                   <code>None</code> )           \u2013            <p>The callback to run when a command is received</p> </li> <li> <code>model_log_level</code>               (<code>int</code>, default:                   <code>INFO</code> )           \u2013            <p>Logging level</p> </li> <li> <code>model_params</code>           \u2013            <p>any other parameter to pass to the whsiper.cpp model see ::: pywhispercpp.constants.PARAMS_SCHEMA</p> </li> </ul> Source code in <code>pywhispercpp/examples/assistant.py</code> <pre><code>def __init__(self,\n             model='tiny',\n             input_device: int = None,\n             silence_threshold: int = 8,\n             q_threshold: int = 16,\n             block_duration: int = 30,\n             commands_callback: Callable[[str], None] = None,\n             model_log_level: int = logging.INFO,\n             **model_params):\n\n    \"\"\"\n    :param model: whisper.cpp model name or a direct path to a`ggml` model\n    :param input_device: The input device (aka microphone), keep it None to take the default\n    :param silence_threshold: The duration of silence after which the inference will be running\n    :param q_threshold: The inference won't be running until the data queue is having at least `q_threshold` elements\n    :param block_duration: minimum time audio updates in ms\n    :param commands_callback: The callback to run when a command is received\n    :param model_log_level: Logging level\n    :param model_params: any other parameter to pass to the whsiper.cpp model see ::: pywhispercpp.constants.PARAMS_SCHEMA\n    \"\"\"\n\n    self.input_device = input_device\n    self.sample_rate = constants.WHISPER_SAMPLE_RATE  # same as whisper.cpp\n    self.channels = 1  # same as whisper.cpp\n    self.block_duration = block_duration\n    self.block_size = int(self.sample_rate * self.block_duration / 1000)\n    self.q = queue.Queue()\n\n    self.vad = webrtcvad.Vad()\n    self.silence_threshold = silence_threshold\n    self.q_threshold = q_threshold\n    self._silence_counter = 0\n\n    self.pwccp_model = Model(model,\n                             log_level=model_log_level,\n                             print_realtime=False,\n                             print_progress=False,\n                             print_timestamps=False,\n                             single_segment=True,\n                             no_context=True,\n                             **model_params)\n    self.commands_callback = commands_callback\n</code></pre>"},{"location":"#pywhispercpp.examples.assistant.Assistant.start","title":"start","text":"<pre><code>start()\n</code></pre> <p>Use this function to start the assistant</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>pywhispercpp/examples/assistant.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"\n    Use this function to start the assistant\n    :return: None\n    \"\"\"\n    logging.info(f\"Starting Assistant ...\")\n    with sd.InputStream(\n            device=self.input_device,  # the default input device\n            channels=self.channels,\n            samplerate=constants.WHISPER_SAMPLE_RATE,\n            blocksize=self.block_size,\n            callback=self._audio_callback):\n\n        try:\n            logging.info(f\"Assistant is listening ... (CTRL+C to stop)\")\n            while True:\n                time.sleep(0.1)\n        except KeyboardInterrupt:\n            logging.info(\"Assistant stopped\")\n</code></pre>"},{"location":"#pywhispercpp.examples.livestream","title":"livestream","text":"<p>Quick and dirty realtime livestream transcription.</p> <p>Not fully satisfying though :) You are welcome to make it better.</p>"},{"location":"#pywhispercpp.examples.livestream.LiveStream","title":"LiveStream","text":"<pre><code>LiveStream(\n    url,\n    model=\"tiny.en\",\n    block_size=1024,\n    buffer_size=20,\n    sample_size=4,\n    output_device=None,\n    model_log_level=logging.CRITICAL,\n    **model_params\n)\n</code></pre> <p>LiveStream class</p> Note <p>It heavily depends on the machine power, the processor will jump quickly to 100% with the wrong parameters.</p> <p>Example usage <pre><code>from pywhispercpp.examples.livestream import LiveStream\n\nurl = \"\"  # Make sure it is a direct stream URL\nls = LiveStream(url=url, n_threads=4)\nls.start()\n</code></pre></p> <p>Parameters:</p> <ul> <li> <code>url</code>           \u2013            <p>Live stream url  <li> <code>model</code>           \u2013            <p>whisper.cpp model</p> </li> <li> <code>block_size</code>               (<code>int</code>, default:                   <code>1024</code> )           \u2013            <p>block size, default to 1024</p> </li> <li> <code>buffer_size</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>number of blocks used for buffering, default to 20</p> </li> <li> <code>sample_size</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>sample size</p> </li> <li> <code>output_device</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>the output device, aka the speaker, leave it None to take the default</p> </li> <li> <code>model_log_level</code>           \u2013            <p>logging level</p> </li> <li> <code>model_params</code>           \u2013            <p>any other whisper.cpp params</p> </li> Source code in <code>pywhispercpp/examples/livestream.py</code> <pre><code>def __init__(self,\n             url,\n             model='tiny.en',\n             block_size: int = 1024,\n             buffer_size: int = 20,\n             sample_size: int = 4,\n             output_device: int = None,\n             model_log_level=logging.CRITICAL,\n             **model_params):\n\n    \"\"\"\n    :param url: Live stream url &lt;a direct stream URL&gt;\n    :param model: whisper.cpp model\n    :param block_size: block size, default to 1024\n    :param buffer_size: number of blocks used for buffering, default to 20\n    :param sample_size: sample size\n    :param output_device: the output device, aka the speaker, leave it None to take the default\n    :param model_log_level: logging level\n    :param model_params: any other whisper.cpp params\n    \"\"\"\n    self.url = url\n    self.block_size = block_size\n    self.buffer_size = buffer_size\n    self.sample_size = sample_size\n    self.output_device = output_device\n\n    self.channels = 1\n    self.samplerate = constants.WHISPER_SAMPLE_RATE\n\n    self.q = queue.Queue(maxsize=buffer_size)\n    self.audio_data = np.array([])\n\n    self.pwccp_model = Model(model,\n                             log_level=model_log_level,\n                             print_realtime=True,\n                             print_progress=False,\n                             print_timestamps=False,\n                             single_segment=True,\n                             **model_params)\n</code></pre>"},{"location":"#pywhispercpp.examples.main","title":"main","text":"<p>A simple Command Line Interface to test the package</p>"},{"location":"#pywhispercpp.examples.recording","title":"recording","text":"<p>A simple example showcasing how to use pywhispercpp to transcribe a recording.</p>"},{"location":"#pywhispercpp.examples.recording.Recording","title":"Recording","text":"<pre><code>Recording(duration, model='tiny.en', **model_params)\n</code></pre> <p>Recording class</p> <p>Example usage <pre><code>from pywhispercpp.examples.recording import Recording\n\nmyrec = Recording(5)\nmyrec.start()\n</code></pre></p> Source code in <code>pywhispercpp/examples/recording.py</code> <pre><code>def __init__(self,\n             duration: int,\n             model: str = 'tiny.en',\n             **model_params):\n    self.duration = duration\n    self.sample_rate = pywhispercpp.constants.WHISPER_SAMPLE_RATE\n    self.channels = 1\n    self.pwcpp_model = Model(model, print_realtime=True, **model_params)\n</code></pre>"}]}